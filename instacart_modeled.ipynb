{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I: Modeling Instacart Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following changes include joinining of tables with similar attributes, addition of primary keys to to all tables missing one, and basic cleaning of data, such as dropping uneccesary columns for our purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 'responsive-cab-267123:instacart_modeled' successfully created.\n"
     ]
    }
   ],
   "source": [
    "dataset_id = \"instacart_modeled\"\n",
    "!bq --location=US mk --dataset {dataset_id}  #Note: This will not work if you already have a dataset with this name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following tables do not need alterations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aisles Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "create table instacart_modeled.Aisles as select * from instacart_staging.Aisles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aisle_id</th>\n",
       "      <th>aisle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "      <td>popcorn jerky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33</td>\n",
       "      <td>kosher foods</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>122</td>\n",
       "      <td>meat counter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>123</td>\n",
       "      <td>packaged vegetables fruits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>103</td>\n",
       "      <td>ice cream toppings</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   aisle_id                       aisle\n",
       "0        23               popcorn jerky\n",
       "1        33                kosher foods\n",
       "2       122                meat counter\n",
       "3       123  packaged vegetables fruits\n",
       "4       103          ice cream toppings"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery \n",
    "select * from instacart_modeled.Aisles limit 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Departments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "create table instacart_modeled.Departments as select * from instacart_staging.Departments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>department_id</th>\n",
       "      <th>department</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>alcohol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "      <td>canned goods</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>dairy eggs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>pets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   department_id    department\n",
       "0              5       alcohol\n",
       "1             15  canned goods\n",
       "2             16    dairy eggs\n",
       "3              8          pets\n",
       "4              2         other"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery \n",
    "select * from instacart_modeled.Departments limit 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "create table instacart_modeled.Products as select * from instacart_staging.Products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_name</th>\n",
       "      <th>aisle_id</th>\n",
       "      <th>department_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9676</td>\n",
       "      <td>Egg, Bacon &amp; Cheese Breakfast Taquitos</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16363</td>\n",
       "      <td>Gluten Free Breaded Chicken Breast Tenders</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23095</td>\n",
       "      <td>Flame Grilled Beef Patty</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32547</td>\n",
       "      <td>Bite Size Turkey Meatball</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>45845</td>\n",
       "      <td>Battered Whole Fish Fillet</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id                                product_name  aisle_id  \\\n",
       "0        9676      Egg, Bacon & Cheese Breakfast Taquitos        34   \n",
       "1       16363  Gluten Free Breaded Chicken Breast Tenders        34   \n",
       "2       23095                    Flame Grilled Beef Patty        34   \n",
       "3       32547                   Bite Size Turkey Meatball        34   \n",
       "4       45845                  Battered Whole Fish Fillet        34   \n",
       "\n",
       "   department_id  \n",
       "0              1  \n",
       "1              1  \n",
       "2              1  \n",
       "3              1  \n",
       "4              1  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery \n",
    "select * from instacart_modeled.Products limit 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All tables have appropriate data types representative of the data in each attribute. Therefore, no casting was done.\n",
    "\n",
    "The modeling focuses on:\n",
    "* dropping attributes that don't yield useful data for our purpse (Orders)\n",
    "* joining tables with the same attributes (Order_Products_Prior and Order_Products_Train)\n",
    "* adding primary keys to all tables (Order_Products_Prior, Order_Products_Train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping Uncessary Columns on Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alterations to 'Orders' table\n",
    "* The eval_set attribute is no longer needed because the two evaluation set tables have been merged.\n",
    "* The days_since_prior_order attribute is not needed because it only contains nulls and floats, which are not useful for our analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following query shows how the days_since_prior_order attribute only yields 0.0s and nulls, which isn't very useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>days_since_prior_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [days_since_prior_order]\n",
       "Index: []"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "select days_since_prior_order from instacart_staging.Orders where days_since_prior_order not in (null, 0.0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "create table instacart_modeled.Orders as select order_id, user_id, order_number, order_dow, order_hour_of_day from instacart_staging.Orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>order_number</th>\n",
       "      <th>order_dow</th>\n",
       "      <th>order_hour_of_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2688538</td>\n",
       "      <td>47867</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2420789</td>\n",
       "      <td>198165</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>742407</td>\n",
       "      <td>199989</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>921979</td>\n",
       "      <td>21991</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1936280</td>\n",
       "      <td>41896</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   order_id  user_id  order_number  order_dow  order_hour_of_day\n",
       "0   2688538    47867            43          0                  1\n",
       "1   2420789   198165            54          0                  2\n",
       "2    742407   199989            50          0                  5\n",
       "3    921979    21991            61          0                  3\n",
       "4   1936280    41896            44          0                  1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery \n",
    "select * from instacart_modeled.Orders limit 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Joining Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Order_Products_Prior and Order_Products_Train tables have the same attributes. After checking documentation on the dataset, we found that merging these two tables without accounting which evaluation set each record was taken from would fit best for our purposes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "create table instacart_modeled.Order_Products as \n",
    "select * from instacart_staging.Order_Products_Prior\n",
    "union distinct \n",
    "select * from instacart_staging.Order_Products_Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Displaying merged of table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>add_to_cart_order</th>\n",
       "      <th>reordered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76181</td>\n",
       "      <td>43768</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2492557</td>\n",
       "      <td>7361</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1347843</td>\n",
       "      <td>26194</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>843703</td>\n",
       "      <td>7188</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2960599</td>\n",
       "      <td>15006</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>510317</td>\n",
       "      <td>10545</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1626114</td>\n",
       "      <td>18987</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>676086</td>\n",
       "      <td>48437</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>993081</td>\n",
       "      <td>40264</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1945159</td>\n",
       "      <td>32402</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>327986</td>\n",
       "      <td>4410</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3337970</td>\n",
       "      <td>27411</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    order_id  product_id  add_to_cart_order  reordered\n",
       "0      76181       43768                 43          0\n",
       "1    2492557        7361                 27          0\n",
       "2    1347843       26194                 33          0\n",
       "3     843703        7188                 29          0\n",
       "4    2960599       15006                 28          0\n",
       "5     510317       10545                 40          0\n",
       "6    1626114       18987                 28          0\n",
       "7     676086       48437                 32          0\n",
       "8     993081       40264                 31          0\n",
       "9    1945159       32402                 26          0\n",
       "10    327986        4410                 38          0\n",
       "11   3337970       27411                 49          0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "select * from instacart_modeled.Order_Products limit 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Primary Keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All tables in our dataset had valid primary keys with the exception of the Order_Products_Prior and Order_Products_Train tables, which are now merged into 'Order_Products' table. The query below shows that making a composite key out of order_id and product_id is valid in the newly merged table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33819106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        f0_\n",
       "0  33819106"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "select count(*) from instacart_modeled.Order_Products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33819106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        f0_\n",
       "0  33819106"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "select count(*) from (select distinct order_id, product_id from instacart_modeled.Order_Products) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II: Writing Join Queries with the Modeled Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Query 1: This query displays what products are in what orders where the aisle is \"instant foods\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frequency</th>\n",
       "      <th>product_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11316</td>\n",
       "      <td>Organic Macaroni Shells &amp; Real Aged Cheddar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8648</td>\n",
       "      <td>Macaroni Shells &amp; White Cheddar Cheese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8435</td>\n",
       "      <td>Bunny Pasta with Yummy Cheese Macaroni &amp; Cheese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7832</td>\n",
       "      <td>Shells &amp; Real Aged Cheddar Macaroni &amp; Cheese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6596</td>\n",
       "      <td>Organic Shells And White Cheddar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6494</td>\n",
       "      <td>Garlic Couscous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6397</td>\n",
       "      <td>Macaroni &amp; Cheese Dinner Original Flavor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5144</td>\n",
       "      <td>Creamy Deluxe Shells &amp; Real Aged Cheddar Sauce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4712</td>\n",
       "      <td>Spanish Rice Pilaf Mix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3863</td>\n",
       "      <td>Parmesan Couscous Mix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3555</td>\n",
       "      <td>Gluten Free Cheddar Macaroni &amp; Cheese Rice Pasta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3428</td>\n",
       "      <td>Chicken Flavor Ramen Noodle Soup</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    frequency                                      product_name\n",
       "0       11316       Organic Macaroni Shells & Real Aged Cheddar\n",
       "1        8648            Macaroni Shells & White Cheddar Cheese\n",
       "2        8435   Bunny Pasta with Yummy Cheese Macaroni & Cheese\n",
       "3        7832      Shells & Real Aged Cheddar Macaroni & Cheese\n",
       "4        6596                  Organic Shells And White Cheddar\n",
       "5        6494                                   Garlic Couscous\n",
       "6        6397          Macaroni & Cheese Dinner Original Flavor\n",
       "7        5144    Creamy Deluxe Shells & Real Aged Cheddar Sauce\n",
       "8        4712                            Spanish Rice Pilaf Mix\n",
       "9        3863                             Parmesan Couscous Mix\n",
       "10       3555  Gluten Free Cheddar Macaroni & Cheese Rice Pasta\n",
       "11       3428                  Chicken Flavor Ramen Noodle Soup"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "select count(*) as frequency, product_name\n",
    "from instacart_modeled.Products p join instacart_modeled.Order_Products o on p.product_id = o.product_id\n",
    "join instacart_modeled.Aisles a on a.aisle_id = p.aisle_id\n",
    "where a.aisle = 'instant foods'\n",
    "group by product_name\n",
    "order by frequency desc\n",
    "limit 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Query 2: This query displays what each user ordered at any point, sorted by order number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>order_number</th>\n",
       "      <th>product_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Organic Unsweetened Vanilla Almond Milk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>XL Pick-A-Size Paper Towel Rolls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Soda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Aged White Cheddar Popcorn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Original Beef Jerky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Soda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Aged White Cheddar Popcorn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Bag of Organic Bananas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Pistachios</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Original Beef Jerky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Cinnamon Toast Crunch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Creamy Almond Butter</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_id  order_number                             product_name\n",
       "0         1             1  Organic Unsweetened Vanilla Almond Milk\n",
       "1         1             1         XL Pick-A-Size Paper Towel Rolls\n",
       "2         1             1                                     Soda\n",
       "3         1             1               Aged White Cheddar Popcorn\n",
       "4         1             1                      Original Beef Jerky\n",
       "5         1             2                                     Soda\n",
       "6         1             2               Aged White Cheddar Popcorn\n",
       "7         1             2                   Bag of Organic Bananas\n",
       "8         1             2                               Pistachios\n",
       "9         1             2                      Original Beef Jerky\n",
       "10        1             2                    Cinnamon Toast Crunch\n",
       "11        1             3                     Creamy Almond Butter"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "select o.user_id, o.order_number, p.product_name\n",
    "from instacart_modeled.Products p join instacart_modeled.Order_Products op on p.product_id = op.product_id\n",
    "join instacart_modeled.Orders o on op.order_id = o.order_id\n",
    "order by user_id, order_number\n",
    "limit 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Query 3: This query displays which users are most frequently purchasing baby products (aisles 82 and 92)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>128627</td>\n",
       "      <td>820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>84092</td>\n",
       "      <td>555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>124042</td>\n",
       "      <td>450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21463</td>\n",
       "      <td>427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8812</td>\n",
       "      <td>378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>111128</td>\n",
       "      <td>373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>197502</td>\n",
       "      <td>369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>169991</td>\n",
       "      <td>366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>58919</td>\n",
       "      <td>358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>108736</td>\n",
       "      <td>354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>21332</td>\n",
       "      <td>348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>113144</td>\n",
       "      <td>345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_id  freq\n",
       "0    128627   820\n",
       "1     84092   555\n",
       "2    124042   450\n",
       "3     21463   427\n",
       "4      8812   378\n",
       "5    111128   373\n",
       "6    197502   369\n",
       "7    169991   366\n",
       "8     58919   358\n",
       "9    108736   354\n",
       "10    21332   348\n",
       "11   113144   345"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "select user_id, count(*) as freq\n",
    "from instacart_modeled.Products p join instacart_modeled.Order_Products op on p.product_id = op.product_id\n",
    "join instacart_modeled.Orders o on o.order_id = op.order_id\n",
    "where aisle_id = 92 or aisle_id = 82\n",
    "group by user_id\n",
    "order by freq desc\n",
    "limit 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Query 4: This query determines the most popular aisles that users shop from, sorted from most to least popular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>freq</th>\n",
       "      <th>aisle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3792661</td>\n",
       "      <td>fresh fruits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3568630</td>\n",
       "      <td>fresh vegetables</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1843806</td>\n",
       "      <td>packaged vegetables fruits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1507583</td>\n",
       "      <td>yogurt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1021462</td>\n",
       "      <td>packaged cheese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>923659</td>\n",
       "      <td>milk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>878150</td>\n",
       "      <td>water seltzer sparkling water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>753739</td>\n",
       "      <td>chips pretzels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>664493</td>\n",
       "      <td>soy lactosefree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>608469</td>\n",
       "      <td>bread</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>599109</td>\n",
       "      <td>refrigerated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>545107</td>\n",
       "      <td>frozen produce</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       freq                          aisle\n",
       "0   3792661                   fresh fruits\n",
       "1   3568630               fresh vegetables\n",
       "2   1843806     packaged vegetables fruits\n",
       "3   1507583                         yogurt\n",
       "4   1021462                packaged cheese\n",
       "5    923659                           milk\n",
       "6    878150  water seltzer sparkling water\n",
       "7    753739                 chips pretzels\n",
       "8    664493                soy lactosefree\n",
       "9    608469                          bread\n",
       "10   599109                   refrigerated\n",
       "11   545107                 frozen produce"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "select  count(*) as freq, aisle\n",
    "from instacart_modeled.Orders o join instacart_modeled.Order_Products op on o.order_id = op.order_id\n",
    "join instacart_modeled.Products p on p.product_id = op.product_id\n",
    "join instacart_modeled.Aisles a on p.aisle_id = a.aisle_id\n",
    "group by aisle\n",
    "order by freq desc\n",
    "limit 12\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Query 5: This query determines the users who purchase the most items (with no cost specified) from instacart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201268</td>\n",
       "      <td>3725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>129928</td>\n",
       "      <td>3689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>164055</td>\n",
       "      <td>3089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>176478</td>\n",
       "      <td>2952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>186704</td>\n",
       "      <td>2936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>137629</td>\n",
       "      <td>2931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>182401</td>\n",
       "      <td>2929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>33731</td>\n",
       "      <td>2912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>108187</td>\n",
       "      <td>2760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4694</td>\n",
       "      <td>2735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>79106</td>\n",
       "      <td>2631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5360</td>\n",
       "      <td>2602</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_id  freq\n",
       "0    201268  3725\n",
       "1    129928  3689\n",
       "2    164055  3089\n",
       "3    176478  2952\n",
       "4    186704  2936\n",
       "5    137629  2931\n",
       "6    182401  2929\n",
       "7     33731  2912\n",
       "8    108187  2760\n",
       "9      4694  2735\n",
       "10    79106  2631\n",
       "11     5360  2602"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "select user_id, count(*) as freq\n",
    "from instacart_modeled.Orders o join instacart_modeled.Order_Products op on o.order_id = op.order_id\n",
    "join instacart_modeled.Products p on p.product_id = op.product_id\n",
    "group by user_id\n",
    "order by freq desc\n",
    "limit 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Query 6: This query can help to determine how many orders have frozen items in them. This could be used to decide whether Instacart should start distributing frozen coolers to its drivers so that the company can ensure its frozen demands are being met."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>freq_of_frozen_purchases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>166124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   freq_of_frozen_purchases\n",
       "0                    166124"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "select count(distinct user_id) as freq_of_frozen_purchases\n",
    "from instacart_modeled.Orders o join instacart_modeled.Order_Products op on o.order_id = op.order_id\n",
    "join instacart_modeled.Products p on p.product_id = op.product_id \n",
    "join instacart_modeled.Departments d on p.department_id = d.department_id\n",
    "where department = 'frozen'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MILESTONE 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Casting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following query returned 0 results in our last milestone when searching for column values other than 0, 0.0 or null. The query showed that this column did not yield useful data for analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>days_since_prior_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [days_since_prior_order]\n",
       "Index: []"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "select days_since_prior_order from instacart_staging.Orders where days_since_prior_order not in (null, 0.0, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This query returns the same empty result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>eval_set</th>\n",
       "      <th>order_number</th>\n",
       "      <th>order_dow</th>\n",
       "      <th>order_hour_of_day</th>\n",
       "      <th>days_since_prior_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [order_id, user_id, eval_set, order_number, order_dow, order_hour_of_day, days_since_prior_order]\n",
       "Index: []"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "select * from instacart_staging.Orders where days_since_prior_order not in (null, 0.0, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Searching for values between 1.0 and 30.0 (from documentation) returns a non-empty value. I'm unsure why the two queries before returned a false result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>eval_set</th>\n",
       "      <th>order_number</th>\n",
       "      <th>order_dow</th>\n",
       "      <th>order_hour_of_day</th>\n",
       "      <th>days_since_prior_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1630627</td>\n",
       "      <td>54</td>\n",
       "      <td>prior</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3287976</td>\n",
       "      <td>190</td>\n",
       "      <td>prior</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1403692</td>\n",
       "      <td>262</td>\n",
       "      <td>prior</td>\n",
       "      <td>37</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1712783</td>\n",
       "      <td>313</td>\n",
       "      <td>prior</td>\n",
       "      <td>86</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3341750</td>\n",
       "      <td>313</td>\n",
       "      <td>prior</td>\n",
       "      <td>98</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1710899</td>\n",
       "      <td>409</td>\n",
       "      <td>prior</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>750107</td>\n",
       "      <td>409</td>\n",
       "      <td>prior</td>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1865455</td>\n",
       "      <td>786</td>\n",
       "      <td>prior</td>\n",
       "      <td>74</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2698935</td>\n",
       "      <td>1024</td>\n",
       "      <td>prior</td>\n",
       "      <td>59</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1452111</td>\n",
       "      <td>1246</td>\n",
       "      <td>prior</td>\n",
       "      <td>39</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   order_id  user_id eval_set  order_number  order_dow  order_hour_of_day  \\\n",
       "0   1630627       54    prior            33          1                  1   \n",
       "1   3287976      190    prior             6          6                  2   \n",
       "2   1403692      262    prior            37          3                  2   \n",
       "3   1712783      313    prior            86          5                  4   \n",
       "4   3341750      313    prior            98          4                  3   \n",
       "5   1710899      409    prior            31          4                  4   \n",
       "6    750107      409    prior            50          3                  1   \n",
       "7   1865455      786    prior            74          3                  4   \n",
       "8   2698935     1024    prior            59          6                  2   \n",
       "9   1452111     1246    prior            39          4                  1   \n",
       "\n",
       "   days_since_prior_order  \n",
       "0                     2.0  \n",
       "1                     2.0  \n",
       "2                     2.0  \n",
       "3                     2.0  \n",
       "4                     2.0  \n",
       "5                     2.0  \n",
       "6                     2.0  \n",
       "7                     2.0  \n",
       "8                     2.0  \n",
       "9                     2.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "select * from instacart_staging.Orders where days_since_prior_order between 1.0 and 30.0 limit 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This column is useful and should be added to our table again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "drop table instacart_modeled.Orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "create table instacart_modeled.Orders as \n",
    "select order_id, user_id, order_number, order_dow, order_hour_of_day, cast(days_since_prior_order as int64) as days_since_prior_order\n",
    "from instacart_staging.Orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>order_number</th>\n",
       "      <th>order_dow</th>\n",
       "      <th>order_hour_of_day</th>\n",
       "      <th>days_since_prior_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2847109</td>\n",
       "      <td>15026</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3045723</td>\n",
       "      <td>15032</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2537448</td>\n",
       "      <td>20322</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1024842</td>\n",
       "      <td>72224</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>749230</td>\n",
       "      <td>115103</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   order_id  user_id  order_number  order_dow  order_hour_of_day  \\\n",
       "0   2847109    15026             1          0                  2   \n",
       "1   3045723    15032             1          0                  5   \n",
       "2   2537448    20322             1          0                  2   \n",
       "3   1024842    72224             1          0                  2   \n",
       "4    749230   115103             1          0                  2   \n",
       "\n",
       "  days_since_prior_order  \n",
       "0                   None  \n",
       "1                   None  \n",
       "2                   None  \n",
       "3                   None  \n",
       "4                   None  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "select * from instacart_modeled.Orders limit 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking Primary Keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aisles\n",
    "`aisle_id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   f0_\n",
       "0  134"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "select count(*) from instacart_modeled.Aisles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   f0_\n",
       "0  134"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "select count(distinct aisle_id) from instacart_modeled.Aisles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Departments \n",
    "`department_id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   f0_\n",
       "0   21"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "select count(*) from instacart_modeled.Departments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   f0_\n",
       "0   21"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "select count(distinct department_id) from instacart_modeled.Departments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Orders\n",
    "`order_id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3421083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       f0_\n",
       "0  3421083"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "select count(*) from instacart_modeled.Orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3421083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       f0_\n",
       "0  3421083"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "select count(distinct order_id) from instacart_modeled.Orders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Products\n",
    "`product_id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49688</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     f0_\n",
       "0  49688"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "select count(*) from instacart_modeled.Products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49688</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     f0_\n",
       "0  49688"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "select count(distinct product_id) from instacart_modeled.Products"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Order_Products\n",
    "`order_id, product_id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33819106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        f0_\n",
       "0  33819106"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "select count(*) from instacart_modeled.Order_Products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33819106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        f0_\n",
       "0  33819106"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "select count(*) from (select distinct order_id, product_id from instacart_modeled.Order_Products)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beam Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This transformation is not needed but done to practice beams.  \n",
    "The days of the week in `order_dow` are represented by integers 0-6.  \n",
    "The beam changes this attribute to a string type with Sunday being 0, Monday 1, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_dow</th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>600905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>587478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>467260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>436972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>426339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>453368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>448761</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   order_dow     f0_\n",
       "0          0  600905\n",
       "1          1  587478\n",
       "2          2  467260\n",
       "3          3  436972\n",
       "4          4  426339\n",
       "5          5  453368\n",
       "6          6  448761"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "select order_dow, count(*) \n",
    "from instacart_modeled.Orders\n",
    "group by order_dow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.runners.interactive.interactive_environment:Interactive Beam requires Python 3.5.3+.\n",
      "WARNING:apache_beam.runners.interactive.interactive_environment:Dependencies required for Interactive Beam PCollection visualization are not available, please use: `pip install apache-beam[interactive]` to install necessary dependencies to enable all data visualization features.\n",
      "/home/jupyter/venv/lib/python3.5/site-packages/apache_beam/io/gcp/bigquery.py:1421: BeamDeprecationWarning: options is deprecated since First stable release. References to <pipeline>.options will not be supported\n",
      "  experiments = p.options.view_as(DebugOptions).experiments or []\n",
      "INFO:apache_beam.runners.direct.direct_runner:Running pipeline with DirectRunner.\n",
      "INFO:apache_beam.internal.gcp.auth:Setting socket default timeout to 60 seconds.\n",
      "INFO:apache_beam.internal.gcp.auth:socket default timeout is 60.0 seconds.\n",
      "INFO:oauth2client.transport:Attempting refresh to obtain initial access_token\n",
      "INFO:apache_beam.io.gcp.bigquery_tools:Using location 'US' from table <TableReference\n",
      " datasetId: 'instacart_modeled'\n",
      " projectId: 'responsive-cab-267123'\n",
      " tableId: 'Orders'> referenced by query SELECT * FROM instacart_modeled.Orders limit 100\n",
      "WARNING:apache_beam.io.gcp.bigquery_tools:Dataset responsive-cab-267123:temp_dataset_3a549dd71b8044d5907fcb43114d26be does not exist so we will create it as temporary with location=US\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current dow: 0\n",
      "new dow: sunday\n",
      "current dow: 0\n",
      "new dow: sunday\n",
      "current dow: 0\n",
      "new dow: sunday\n",
      "current dow: 0\n",
      "new dow: sunday\n",
      "current dow: 0\n",
      "new dow: sunday\n",
      "current dow: 0\n",
      "new dow: sunday\n",
      "current dow: 0\n",
      "new dow: sunday\n",
      "current dow: 0\n",
      "new dow: sunday\n",
      "current dow: 0\n",
      "new dow: sunday\n",
      "current dow: 0\n",
      "new dow: sunday\n",
      "current dow: 0\n",
      "new dow: sunday\n",
      "current dow: 0\n",
      "new dow: sunday\n",
      "current dow: 0\n",
      "new dow: sunday\n",
      "current dow: 0\n",
      "new dow: sunday\n",
      "current dow: 0\n",
      "new dow: sunday\n",
      "current dow: 0\n",
      "new dow: sunday\n",
      "current dow: 0\n",
      "new dow: sunday\n",
      "current dow: 0\n",
      "new dow: sunday\n",
      "current dow: 0\n",
      "new dow: sunday\n",
      "current dow: 0\n",
      "new dow: sunday\n",
      "current dow: 0\n",
      "new dow: sunday\n",
      "current dow: 0\n",
      "new dow: sunday\n",
      "current dow: 0\n",
      "new dow: sunday\n",
      "current dow: 0\n",
      "new dow: sunday\n",
      "current dow: 0\n",
      "new dow: sunday\n",
      "current dow: 0\n",
      "new dow: sunday\n",
      "current dow: 0\n",
      "new dow: sunday\n",
      "current dow: 0\n",
      "new dow: sunday\n",
      "current dow: 0\n",
      "new dow: sunday\n",
      "current dow: 0\n",
      "new dow: sunday\n",
      "current dow: 0\n",
      "new dow: sunday\n",
      "current dow: 0\n",
      "new dow: sunday\n",
      "current dow: 0\n",
      "new dow: sunday\n",
      "current dow: 0\n",
      "new dow: sunday\n",
      "current dow: 0\n",
      "new dow: sunday\n",
      "current dow: 0\n",
      "new dow: sunday\n",
      "current dow: 0\n",
      "new dow: sunday\n",
      "current dow: 0\n",
      "new dow: sunday\n",
      "current dow: 0\n",
      "new dow: sunday\n",
      "current dow: 0\n",
      "new dow: sunday\n",
      "current dow: 0\n",
      "new dow: sunday\n",
      "current dow: 0\n",
      "new dow: sunday\n",
      "current dow: 0\n",
      "new dow: sunday\n",
      "current dow: 0\n",
      "new dow: sunday\n",
      "current dow: 0\n",
      "new dow: sunday\n",
      "current dow: 0\n",
      "new dow: sunday\n",
      "current dow: 0\n",
      "new dow: sunday\n",
      "current dow: 0\n",
      "new dow: sunday\n",
      "current dow: 0\n",
      "new dow: sunday\n",
      "current dow: 0\n",
      "new dow: sunday\n",
      "current dow: 0\n",
      "new dow: sunday\n",
      "current dow: 0\n",
      "new dow: sunday\n",
      "current dow: 0\n",
      "new dow: sunday\n",
      "current dow: 0\n",
      "new dow: sunday\n",
      "current dow: 0\n",
      "new dow: sunday\n",
      "current dow: 0\n",
      "new dow: sunday\n",
      "current dow: 0\n",
      "new dow: sunday\n",
      "current dow: 0\n",
      "new dow: sunday\n",
      "current dow: 0\n",
      "new dow: sunday\n",
      "current dow: 0\n",
      "new dow: sunday\n",
      "current dow: 0\n",
      "new dow: sunday\n",
      "current dow: 0\n",
      "new dow: sunday\n",
      "current dow: 0\n",
      "new dow: sunday\n",
      "current dow: 0\n",
      "new dow: sunday\n",
      "current dow: 0\n",
      "new dow: sunday\n",
      "current dow: 0\n",
      "new dow: sunday\n",
      "current dow: 0\n",
      "new dow: sunday\n",
      "current dow: 0\n",
      "new dow: sunday\n",
      "current dow: 0\n",
      "new dow: sunday\n",
      "current dow: 0\n",
      "new dow: sunday\n",
      "current dow: 0\n",
      "new dow: sunday\n",
      "current dow: 0\n",
      "new dow: sunday\n",
      "current dow: 0\n",
      "new dow: sunday\n",
      "current dow: 0\n",
      "new dow: sunday\n",
      "current dow: 0\n",
      "new dow: sunday\n",
      "current dow: 0\n",
      "new dow: sunday\n",
      "current dow: 0\n",
      "new dow: sunday\n",
      "current dow: 0\n",
      "new dow: sunday\n",
      "current dow: 0\n",
      "new dow: sunday\n",
      "current dow: 0\n",
      "new dow: sunday\n",
      "current dow: 0\n",
      "new dow: sunday\n",
      "current dow: 0\n",
      "new dow: sunday\n",
      "current dow: 0\n",
      "new dow: sunday\n",
      "current dow: 0\n",
      "new dow: sunday\n",
      "current dow: 0\n",
      "new dow: sunday\n",
      "current dow: 0\n",
      "new dow: sunday\n",
      "current dow: 0\n",
      "new dow: sunday\n",
      "current dow: 0\n",
      "new dow: sunday\n",
      "current dow: 0\n",
      "new dow: sunday\n",
      "current dow: 0\n",
      "new dow: sunday\n",
      "current dow: 0\n",
      "new dow: sunday\n",
      "current dow: 0\n",
      "new dow: sunday\n",
      "current dow: 0\n",
      "new dow: sunday\n",
      "current dow: 0\n",
      "new dow: sunday\n",
      "current dow: 0\n",
      "new dow: sunday\n",
      "current dow: 0\n",
      "new dow: sunday\n",
      "current dow: 0\n",
      "new dow: sunday\n",
      "current dow: 0\n",
      "new dow: sunday\n",
      "current dow: 0\n",
      "new dow: sunday\n",
      "current dow: 0\n",
      "new dow: sunday\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:apache_beam.io.gcp.bigquery_tools:Created table responsive-cab-267123.instacart_modeled.Orders_Beam with schema <TableSchema\n",
      " fields: [<TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'order_id'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'user_id'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'order_number'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'order_dow'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'order_hour_of_day'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'days_since_prior_order'\n",
      " type: 'INTEGER'>]>. Result: <Table\n",
      " creationTime: 1583113459989\n",
      " etag: 'rL5K9+j+2psvG/mIln6sow=='\n",
      " id: 'responsive-cab-267123:instacart_modeled.Orders_Beam'\n",
      " kind: 'bigquery#table'\n",
      " lastModifiedTime: 1583113460041\n",
      " location: 'US'\n",
      " numBytes: 0\n",
      " numLongTermBytes: 0\n",
      " numRows: 0\n",
      " schema: <TableSchema\n",
      " fields: [<TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'order_id'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'user_id'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'order_number'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'order_dow'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'order_hour_of_day'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'days_since_prior_order'\n",
      " type: 'INTEGER'>]>\n",
      " selfLink: 'https://www.googleapis.com/bigquery/v2/projects/responsive-cab-267123/datasets/instacart_modeled/tables/Orders_Beam'\n",
      " tableReference: <TableReference\n",
      " datasetId: 'instacart_modeled'\n",
      " projectId: 'responsive-cab-267123'\n",
      " tableId: 'Orders_Beam'>\n",
      " type: 'TABLE'>.\n",
      "WARNING:apache_beam.io.gcp.bigquery_tools:Sleeping for 150 seconds before the write as BigQuery inserts can be routed to deleted table for 2 mins after the delete and create.\n",
      "INFO:apache_beam.io.filebasedsink:Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "INFO:apache_beam.io.filebasedsink:Renamed 1 shards in 0.11 seconds.\n",
      "INFO:apache_beam.io.filebasedsink:Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "INFO:apache_beam.io.filebasedsink:Renamed 1 shards in 0.10 seconds.\n"
     ]
    }
   ],
   "source": [
    "%run Orders_beam.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_dow</th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sunday</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  order_dow  f0_\n",
       "0    sunday  100"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "select order_dow, count(*) \n",
    "from instacart_modeled.Orders_Beam\n",
    "group by order_dow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verifying Primary Key in Orders_Beam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   f0_\n",
       "0  100"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "select count(*) from instacart_modeled.Orders_Beam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   f0_\n",
       "0  100"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "select count(distinct order_id) from instacart_modeled.Orders_Beam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Milestone 5 Dataflow Beam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.options.pipeline_options:--region not set; will default to us-central1. Future releases of Beam will require the user to set --region explicitly, or else have a default set via the gcloud tool. https://cloud.google.com/compute/docs/regions-zones\n",
      "/home/jupyter/venv/lib/python3.5/site-packages/apache_beam/runners/dataflow/dataflow_runner.py:740: BeamDeprecationWarning: BigQuerySink is deprecated since 2.11.0. Use WriteToBigQuery instead.\n",
      "  kms_key=transform.kms_key))\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Starting GCS upload to gs://bmease_cs327e/staging/transform-orders-df.1583727151.869137/pipeline.pb...\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Completed GCS upload to gs://bmease_cs327e/staging/transform-orders-df.1583727151.869137/pipeline.pb in 0 seconds.\n",
      "INFO:apache_beam.runners.portability.stager:Downloading source distribution of the SDK from PyPi\n",
      "INFO:apache_beam.runners.portability.stager:Executing command: ['/home/jupyter/venv/bin/python', '-m', 'pip', 'download', '--dest', '/tmp/tmptg2a7i8x', 'apache-beam==2.19.0', '--no-deps', '--no-binary', ':all:']\n",
      "INFO:apache_beam.runners.portability.stager:Staging SDK sources from PyPI to gs://bmease_cs327e/staging/transform-orders-df.1583727151.869137/dataflow_python_sdk.tar\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Starting GCS upload to gs://bmease_cs327e/staging/transform-orders-df.1583727151.869137/dataflow_python_sdk.tar...\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Completed GCS upload to gs://bmease_cs327e/staging/transform-orders-df.1583727151.869137/dataflow_python_sdk.tar in 0 seconds.\n",
      "INFO:apache_beam.runners.portability.stager:Downloading binary distribution of the SDK from PyPi\n",
      "INFO:apache_beam.runners.portability.stager:Executing command: ['/home/jupyter/venv/bin/python', '-m', 'pip', 'download', '--dest', '/tmp/tmptg2a7i8x', 'apache-beam==2.19.0', '--no-deps', '--only-binary', ':all:', '--python-version', '35', '--implementation', 'cp', '--abi', 'cp35m', '--platform', 'manylinux1_x86_64']\n",
      "INFO:apache_beam.runners.portability.stager:Staging binary distribution of the SDK from PyPI to gs://bmease_cs327e/staging/transform-orders-df.1583727151.869137/apache_beam-2.19.0-cp35-cp35m-manylinux1_x86_64.whl\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Starting GCS upload to gs://bmease_cs327e/staging/transform-orders-df.1583727151.869137/apache_beam-2.19.0-cp35-cp35m-manylinux1_x86_64.whl...\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Completed GCS upload to gs://bmease_cs327e/staging/transform-orders-df.1583727151.869137/apache_beam-2.19.0-cp35-cp35m-manylinux1_x86_64.whl in 1 seconds.\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Create job: <Job\n",
      " createTime: '2020-03-09T04:12:37.756420Z'\n",
      " currentStateTime: '1970-01-01T00:00:00Z'\n",
      " id: '2020-03-08_21_12_36-5131594110521976905'\n",
      " location: 'us-central1'\n",
      " name: 'transform-orders-df'\n",
      " projectId: 'responsive-cab-267123'\n",
      " stageStates: []\n",
      " startTime: '2020-03-09T04:12:37.756420Z'\n",
      " steps: []\n",
      " tempFiles: []\n",
      " type: TypeValueValuesEnum(JOB_TYPE_BATCH, 1)>\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Created job with id: [2020-03-08_21_12_36-5131594110521976905]\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:To access the Dataflow monitoring console, please navigate to https://console.cloud.google.com/dataflow/jobsDetail/locations/us-central1/jobs/2020-03-08_21_12_36-5131594110521976905?project=responsive-cab-267123\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:Job 2020-03-08_21_12_36-5131594110521976905 is in state JOB_STATE_PENDING\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:12:36.622Z: JOB_MESSAGE_DETAILED: Autoscaling is enabled for job 2020-03-08_21_12_36-5131594110521976905. The number of workers will be between 1 and 1000.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:12:36.622Z: JOB_MESSAGE_DETAILED: Autoscaling was automatically enabled for job 2020-03-08_21_12_36-5131594110521976905.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:12:39.746Z: JOB_MESSAGE_DETAILED: Checking permissions granted to controller Service Account.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:12:40.340Z: JOB_MESSAGE_BASIC: Worker configuration: n1-standard-4 in us-central1-c.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:12:40.887Z: JOB_MESSAGE_DETAILED: Expanding CoGroupByKey operations into optimizable parts.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:12:40.922Z: JOB_MESSAGE_DEBUG: Combiner lifting skipped for step Write to output.txt/Write/WriteImpl/GroupByKey: GroupByKey not followed by a combiner.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:12:40.943Z: JOB_MESSAGE_DEBUG: Combiner lifting skipped for step Write to input.txt/Write/WriteImpl/GroupByKey: GroupByKey not followed by a combiner.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:12:40.968Z: JOB_MESSAGE_DETAILED: Expanding GroupByKey operations into optimizable parts.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:12:41.002Z: JOB_MESSAGE_DETAILED: Lifting ValueCombiningMappingFns into MergeBucketsMappingFns\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:12:41.096Z: JOB_MESSAGE_DEBUG: Annotating graph with Autotuner information.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:12:41.325Z: JOB_MESSAGE_DETAILED: Fusing adjacent ParDo, Read, Write, and Flatten operations\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:12:41.347Z: JOB_MESSAGE_DETAILED: Fusing consumer Format DOW into Read from BigQuery\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:12:41.380Z: JOB_MESSAGE_DETAILED: Fusing consumer Write to input.txt/Write/WriteImpl/WriteBundles/WriteBundles into Read from BigQuery\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:12:41.416Z: JOB_MESSAGE_DETAILED: Fusing consumer Write to output.txt/Write/WriteImpl/WriteBundles/WriteBundles into Format DOW\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:12:41.442Z: JOB_MESSAGE_DETAILED: Fusing consumer Write BQ table/WriteToBigQuery/NativeWrite into Format DOW\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:12:41.470Z: JOB_MESSAGE_DETAILED: Fusing consumer Write to input.txt/Write/WriteImpl/Pair into Write to input.txt/Write/WriteImpl/WriteBundles/WriteBundles\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:12:41.503Z: JOB_MESSAGE_DETAILED: Fusing consumer Write to input.txt/Write/WriteImpl/WindowInto(WindowIntoFn) into Write to input.txt/Write/WriteImpl/Pair\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:12:41.527Z: JOB_MESSAGE_DETAILED: Fusing consumer Write to input.txt/Write/WriteImpl/GroupByKey/Reify into Write to input.txt/Write/WriteImpl/WindowInto(WindowIntoFn)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:12:41.551Z: JOB_MESSAGE_DETAILED: Fusing consumer Write to input.txt/Write/WriteImpl/GroupByKey/Write into Write to input.txt/Write/WriteImpl/GroupByKey/Reify\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:12:41.587Z: JOB_MESSAGE_DETAILED: Fusing consumer Write to input.txt/Write/WriteImpl/GroupByKey/GroupByWindow into Write to input.txt/Write/WriteImpl/GroupByKey/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:12:41.611Z: JOB_MESSAGE_DETAILED: Fusing consumer Write to input.txt/Write/WriteImpl/Extract into Write to input.txt/Write/WriteImpl/GroupByKey/GroupByWindow\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:12:41.634Z: JOB_MESSAGE_DETAILED: Fusing consumer Write to output.txt/Write/WriteImpl/Pair into Write to output.txt/Write/WriteImpl/WriteBundles/WriteBundles\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:12:41.659Z: JOB_MESSAGE_DETAILED: Fusing consumer Write to output.txt/Write/WriteImpl/WindowInto(WindowIntoFn) into Write to output.txt/Write/WriteImpl/Pair\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:12:41.698Z: JOB_MESSAGE_DETAILED: Fusing consumer Write to output.txt/Write/WriteImpl/GroupByKey/Reify into Write to output.txt/Write/WriteImpl/WindowInto(WindowIntoFn)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:12:41.731Z: JOB_MESSAGE_DETAILED: Fusing consumer Write to output.txt/Write/WriteImpl/GroupByKey/Write into Write to output.txt/Write/WriteImpl/GroupByKey/Reify\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:12:41.766Z: JOB_MESSAGE_DETAILED: Fusing consumer Write to output.txt/Write/WriteImpl/GroupByKey/GroupByWindow into Write to output.txt/Write/WriteImpl/GroupByKey/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:12:41.800Z: JOB_MESSAGE_DETAILED: Fusing consumer Write to output.txt/Write/WriteImpl/Extract into Write to output.txt/Write/WriteImpl/GroupByKey/GroupByWindow\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:12:41.824Z: JOB_MESSAGE_DETAILED: Fusing consumer Write to input.txt/Write/WriteImpl/InitializeWrite into Write to input.txt/Write/WriteImpl/DoOnce/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:12:41.853Z: JOB_MESSAGE_DETAILED: Fusing consumer Write to output.txt/Write/WriteImpl/InitializeWrite into Write to output.txt/Write/WriteImpl/DoOnce/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:12:41.883Z: JOB_MESSAGE_DEBUG: Workflow config is missing a default resource spec.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:12:41.911Z: JOB_MESSAGE_DEBUG: Adding StepResource setup and teardown to workflow graph.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:12:41.936Z: JOB_MESSAGE_DEBUG: Adding workflow start and stop steps.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:12:41.973Z: JOB_MESSAGE_DEBUG: Assigning stage ids.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:12:42.219Z: JOB_MESSAGE_DEBUG: Executing wait step start29\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:12:42.277Z: JOB_MESSAGE_BASIC: Executing operation Write to output.txt/Write/WriteImpl/DoOnce/Read+Write to output.txt/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:12:42.312Z: JOB_MESSAGE_BASIC: Executing operation Write to input.txt/Write/WriteImpl/DoOnce/Read+Write to input.txt/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:12:42.314Z: JOB_MESSAGE_DEBUG: Starting worker pool setup.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:12:42.343Z: JOB_MESSAGE_BASIC: Executing operation Write to output.txt/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:12:42.350Z: JOB_MESSAGE_BASIC: Starting 1 workers in us-central1-c...\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:12:42.365Z: JOB_MESSAGE_BASIC: Executing operation Write to input.txt/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:12:42.399Z: JOB_MESSAGE_BASIC: Finished operation Write to output.txt/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:12:42.416Z: JOB_MESSAGE_BASIC: Finished operation Write to input.txt/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:12:42.470Z: JOB_MESSAGE_DEBUG: Value \"Write to output.txt/Write/WriteImpl/GroupByKey/Session\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:12:42.493Z: JOB_MESSAGE_DEBUG: Value \"Write to input.txt/Write/WriteImpl/GroupByKey/Session\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:Job 2020-03-08_21_12_36-5131594110521976905 is in state JOB_STATE_RUNNING\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:13:08.544Z: JOB_MESSAGE_DETAILED: Autoscaling: Raised the number of workers to 1 based on the rate of progress in the currently running step(s).\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:14:16.910Z: JOB_MESSAGE_DETAILED: Workers have started successfully.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:14:16.945Z: JOB_MESSAGE_DETAILED: Workers have started successfully.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:14:47.402Z: JOB_MESSAGE_BASIC: Finished operation Write to input.txt/Write/WriteImpl/DoOnce/Read+Write to input.txt/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:14:47.459Z: JOB_MESSAGE_BASIC: Finished operation Write to output.txt/Write/WriteImpl/DoOnce/Read+Write to output.txt/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:14:47.467Z: JOB_MESSAGE_DEBUG: Value \"Write to input.txt/Write/WriteImpl/DoOnce/Read.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:14:47.495Z: JOB_MESSAGE_DEBUG: Value \"Write to input.txt/Write/WriteImpl/InitializeWrite.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:14:47.532Z: JOB_MESSAGE_DEBUG: Value \"Write to output.txt/Write/WriteImpl/DoOnce/Read.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:14:47.567Z: JOB_MESSAGE_DEBUG: Value \"Write to output.txt/Write/WriteImpl/InitializeWrite.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:14:47.602Z: JOB_MESSAGE_BASIC: Executing operation Write to input.txt/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:14:47.629Z: JOB_MESSAGE_BASIC: Executing operation Write to input.txt/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:14:47.645Z: JOB_MESSAGE_BASIC: Finished operation Write to input.txt/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:14:47.666Z: JOB_MESSAGE_BASIC: Executing operation Write to input.txt/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:14:47.684Z: JOB_MESSAGE_BASIC: Finished operation Write to input.txt/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:14:47.689Z: JOB_MESSAGE_BASIC: Executing operation Write to output.txt/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:14:47.714Z: JOB_MESSAGE_BASIC: Executing operation Write to output.txt/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:14:47.723Z: JOB_MESSAGE_BASIC: Finished operation Write to input.txt/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:14:47.744Z: JOB_MESSAGE_BASIC: Finished operation Write to output.txt/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:14:47.750Z: JOB_MESSAGE_BASIC: Executing operation Write to output.txt/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:14:47.776Z: JOB_MESSAGE_BASIC: Finished operation Write to output.txt/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:14:47.786Z: JOB_MESSAGE_DEBUG: Value \"Write to input.txt/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:14:47.812Z: JOB_MESSAGE_BASIC: Finished operation Write to output.txt/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:14:47.812Z: JOB_MESSAGE_DEBUG: Value \"Write to input.txt/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:14:47.844Z: JOB_MESSAGE_DEBUG: Value \"Write to input.txt/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:14:47.881Z: JOB_MESSAGE_DEBUG: Value \"Write to output.txt/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:14:47.919Z: JOB_MESSAGE_DEBUG: Value \"Write to output.txt/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:14:47.952Z: JOB_MESSAGE_DEBUG: Value \"Write to output.txt/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:14:47.978Z: JOB_MESSAGE_BASIC: Executing operation Read from BigQuery+Format DOW+Write to input.txt/Write/WriteImpl/WriteBundles/WriteBundles+Write to output.txt/Write/WriteImpl/WriteBundles/WriteBundles+Write BQ table/WriteToBigQuery/NativeWrite+Write to input.txt/Write/WriteImpl/Pair+Write to input.txt/Write/WriteImpl/WindowInto(WindowIntoFn)+Write to input.txt/Write/WriteImpl/GroupByKey/Reify+Write to input.txt/Write/WriteImpl/GroupByKey/Write+Write to output.txt/Write/WriteImpl/Pair+Write to output.txt/Write/WriteImpl/WindowInto(WindowIntoFn)+Write to output.txt/Write/WriteImpl/GroupByKey/Reify+Write to output.txt/Write/WriteImpl/GroupByKey/Write\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:14:49.086Z: JOB_MESSAGE_BASIC: BigQuery query issued as job: \"dataflow_job_2184620172997353387\". You can check its status with the bq tool: \"bq show -j --project_id=responsive-cab-267123 dataflow_job_2184620172997353387\".\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:16:42.203Z: JOB_MESSAGE_BASIC: BigQuery query completed, job : \"dataflow_job_2184620172997353387\"\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:16:42.548Z: JOB_MESSAGE_BASIC: BigQuery export job \"dataflow_job_5054229300950634750\" started. You can check its status with the bq tool: \"bq show -j --project_id=responsive-cab-267123 dataflow_job_5054229300950634750\".\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:17:12.974Z: JOB_MESSAGE_DETAILED: BigQuery export job progress: \"dataflow_job_5054229300950634750\" observed total of 1 exported files thus far.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:17:13.013Z: JOB_MESSAGE_BASIC: BigQuery export job finished: \"dataflow_job_5054229300950634750\"\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:18:42.193Z: JOB_MESSAGE_DETAILED: Checking permissions granted to controller Service Account.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:19:58.746Z: JOB_MESSAGE_BASIC: Executing BigQuery import job \"dataflow_job_2184620172997351367\". You can check its status with the bq tool: \"bq show -j --project_id=responsive-cab-267123 dataflow_job_2184620172997351367\".\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:20:29.496Z: JOB_MESSAGE_BASIC: BigQuery import job \"dataflow_job_2184620172997351367\" done.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:20:30.002Z: JOB_MESSAGE_BASIC: Finished operation Read from BigQuery+Format DOW+Write to input.txt/Write/WriteImpl/WriteBundles/WriteBundles+Write to output.txt/Write/WriteImpl/WriteBundles/WriteBundles+Write BQ table/WriteToBigQuery/NativeWrite+Write to input.txt/Write/WriteImpl/Pair+Write to input.txt/Write/WriteImpl/WindowInto(WindowIntoFn)+Write to input.txt/Write/WriteImpl/GroupByKey/Reify+Write to input.txt/Write/WriteImpl/GroupByKey/Write+Write to output.txt/Write/WriteImpl/Pair+Write to output.txt/Write/WriteImpl/WindowInto(WindowIntoFn)+Write to output.txt/Write/WriteImpl/GroupByKey/Reify+Write to output.txt/Write/WriteImpl/GroupByKey/Write\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:20:30.091Z: JOB_MESSAGE_BASIC: Executing operation Write to output.txt/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:20:30.128Z: JOB_MESSAGE_BASIC: Executing operation Write to input.txt/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:20:30.144Z: JOB_MESSAGE_BASIC: Finished operation Write to output.txt/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:20:30.176Z: JOB_MESSAGE_BASIC: Finished operation Write to input.txt/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:20:30.217Z: JOB_MESSAGE_BASIC: Executing operation Write to output.txt/Write/WriteImpl/GroupByKey/Read+Write to output.txt/Write/WriteImpl/GroupByKey/GroupByWindow+Write to output.txt/Write/WriteImpl/Extract\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:20:30.258Z: JOB_MESSAGE_BASIC: Executing operation Write to input.txt/Write/WriteImpl/GroupByKey/Read+Write to input.txt/Write/WriteImpl/GroupByKey/GroupByWindow+Write to input.txt/Write/WriteImpl/Extract\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:20:32.597Z: JOB_MESSAGE_BASIC: Finished operation Write to output.txt/Write/WriteImpl/GroupByKey/Read+Write to output.txt/Write/WriteImpl/GroupByKey/GroupByWindow+Write to output.txt/Write/WriteImpl/Extract\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:20:32.679Z: JOB_MESSAGE_DEBUG: Value \"Write to output.txt/Write/WriteImpl/Extract.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:20:32.753Z: JOB_MESSAGE_BASIC: Executing operation Write to output.txt/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:20:32.781Z: JOB_MESSAGE_BASIC: Finished operation Write to input.txt/Write/WriteImpl/GroupByKey/Read+Write to input.txt/Write/WriteImpl/GroupByKey/GroupByWindow+Write to input.txt/Write/WriteImpl/Extract\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:20:32.788Z: JOB_MESSAGE_BASIC: Executing operation Write to output.txt/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:20:32.843Z: JOB_MESSAGE_DEBUG: Value \"Write to input.txt/Write/WriteImpl/Extract.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:20:32.849Z: JOB_MESSAGE_BASIC: Finished operation Write to output.txt/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:20:32.875Z: JOB_MESSAGE_BASIC: Finished operation Write to output.txt/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:20:32.911Z: JOB_MESSAGE_BASIC: Executing operation Write to input.txt/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:20:32.952Z: JOB_MESSAGE_BASIC: Executing operation Write to input.txt/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:20:32.964Z: JOB_MESSAGE_BASIC: Finished operation Write to input.txt/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:20:32.991Z: JOB_MESSAGE_DEBUG: Value \"Write to output.txt/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:20:33.014Z: JOB_MESSAGE_BASIC: Finished operation Write to input.txt/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:20:33.021Z: JOB_MESSAGE_DEBUG: Value \"Write to output.txt/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:20:33.043Z: JOB_MESSAGE_DEBUG: Value \"Write to input.txt/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:20:33.075Z: JOB_MESSAGE_BASIC: Executing operation Write to output.txt/Write/WriteImpl/PreFinalize/PreFinalize\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:20:33.111Z: JOB_MESSAGE_DEBUG: Value \"Write to input.txt/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:20:33.177Z: JOB_MESSAGE_BASIC: Executing operation Write to input.txt/Write/WriteImpl/PreFinalize/PreFinalize\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:20:35.720Z: JOB_MESSAGE_BASIC: Finished operation Write to output.txt/Write/WriteImpl/PreFinalize/PreFinalize\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:20:35.794Z: JOB_MESSAGE_DEBUG: Value \"Write to output.txt/Write/WriteImpl/PreFinalize.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:20:35.872Z: JOB_MESSAGE_BASIC: Executing operation Write to output.txt/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:20:35.939Z: JOB_MESSAGE_BASIC: Finished operation Write to output.txt/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:20:36.001Z: JOB_MESSAGE_DEBUG: Value \"Write to output.txt/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:20:36.040Z: JOB_MESSAGE_BASIC: Finished operation Write to input.txt/Write/WriteImpl/PreFinalize/PreFinalize\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:20:36.064Z: JOB_MESSAGE_BASIC: Executing operation Write to output.txt/Write/WriteImpl/FinalizeWrite/FinalizeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:20:36.107Z: JOB_MESSAGE_DEBUG: Value \"Write to input.txt/Write/WriteImpl/PreFinalize.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:20:36.184Z: JOB_MESSAGE_BASIC: Executing operation Write to input.txt/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:20:36.224Z: JOB_MESSAGE_BASIC: Finished operation Write to input.txt/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:20:36.285Z: JOB_MESSAGE_DEBUG: Value \"Write to input.txt/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:20:36.344Z: JOB_MESSAGE_BASIC: Executing operation Write to input.txt/Write/WriteImpl/FinalizeWrite/FinalizeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:20:37.237Z: JOB_MESSAGE_BASIC: Finished operation Write to output.txt/Write/WriteImpl/FinalizeWrite/FinalizeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:20:38.391Z: JOB_MESSAGE_BASIC: Finished operation Write to input.txt/Write/WriteImpl/FinalizeWrite/FinalizeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:20:38.455Z: JOB_MESSAGE_DEBUG: Executing success step success27\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:20:38.579Z: JOB_MESSAGE_DETAILED: Cleaning up.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:20:38.641Z: JOB_MESSAGE_DEBUG: Starting worker pool teardown.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:20:38.681Z: JOB_MESSAGE_BASIC: Stopping worker pool...\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:22:17.930Z: JOB_MESSAGE_DETAILED: Autoscaling: Resized worker pool from 1 to 0.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:22:17.962Z: JOB_MESSAGE_BASIC: Worker pool stopped.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T04:22:17.991Z: JOB_MESSAGE_DEBUG: Tearing down pending resources...\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:Job 2020-03-08_21_12_36-5131594110521976905 is in state JOB_STATE_DONE\n"
     ]
    }
   ],
   "source": [
    "%run Orders_beam_dataflow.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verifying Primary Key in Orders_Beam_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3421083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       f0_\n",
       "0  3421083"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "select count(*) from instacart_modeled.Orders_Beam_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3421083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       f0_\n",
       "0  3421083"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "select count(distinct order_id) from instacart_modeled.Orders_Beam_DF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Milestone 6 Beam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our datasets were pretty much clean after milestone 4, this transformation analyzes the Order_Products table. The frequency a product appeared in an order and the total amount of times that product was ordered across all orders was analyzed. The outputted table reflects the latter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running both directrunner and dataflow beams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.runners.interactive.interactive_environment:Interactive Beam requires Python 3.5.3+.\n",
      "WARNING:apache_beam.runners.interactive.interactive_environment:Dependencies required for Interactive Beam PCollection visualization are not available, please use: `pip install apache-beam[interactive]` to install necessary dependencies to enable all data visualization features.\n",
      "/home/jupyter/venv/lib/python3.5/site-packages/apache_beam/io/gcp/bigquery.py:1421: BeamDeprecationWarning: options is deprecated since First stable release. References to <pipeline>.options will not be supported\n",
      "  experiments = p.options.view_as(DebugOptions).experiments or []\n",
      "INFO:apache_beam.runners.direct.direct_runner:Running pipeline with DirectRunner.\n",
      "INFO:apache_beam.internal.gcp.auth:Setting socket default timeout to 60 seconds.\n",
      "INFO:apache_beam.internal.gcp.auth:socket default timeout is 60.0 seconds.\n",
      "INFO:oauth2client.transport:Attempting refresh to obtain initial access_token\n",
      "INFO:apache_beam.io.gcp.bigquery_tools:Using location 'US' from table <TableReference\n",
      " datasetId: 'instacart_modeled'\n",
      " projectId: 'responsive-cab-267123'\n",
      " tableId: 'Order_Products'> referenced by query SELECT product_id, add_to_cart_order as total FROM instacart_modeled.Order_Products limit 100\n",
      "WARNING:apache_beam.io.gcp.bigquery_tools:Dataset responsive-cab-267123:temp_dataset_89e86f3f08884969a8f7cdbf6cd35d1d does not exist so we will create it as temporary with location=US\n",
      "INFO:apache_beam.io.filebasedsink:Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "INFO:apache_beam.io.filebasedsink:Renamed 1 shards in 0.10 seconds.\n",
      "INFO:apache_beam.io.filebasedsink:Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "INFO:apache_beam.io.filebasedsink:Renamed 1 shards in 0.10 seconds.\n",
      "INFO:apache_beam.io.filebasedsink:Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "INFO:apache_beam.io.filebasedsink:Renamed 1 shards in 0.10 seconds.\n",
      "INFO:apache_beam.io.filebasedsink:Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "INFO:apache_beam.io.filebasedsink:Renamed 1 shards in 0.10 seconds.\n",
      "INFO:apache_beam.io.gcp.bigquery_tools:Created table responsive-cab-267123.instacart_modeled.Order_Products_Beam with schema <TableSchema\n",
      " fields: [<TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'product_id'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'total'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'frequency'\n",
      " type: 'INTEGER'>]>. Result: <Table\n",
      " creationTime: 1583733867186\n",
      " etag: 'ZeGyWzNuLkNj7j8SXeBv+A=='\n",
      " id: 'responsive-cab-267123:instacart_modeled.Order_Products_Beam'\n",
      " kind: 'bigquery#table'\n",
      " lastModifiedTime: 1583733867220\n",
      " location: 'US'\n",
      " numBytes: 0\n",
      " numLongTermBytes: 0\n",
      " numRows: 0\n",
      " schema: <TableSchema\n",
      " fields: [<TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'product_id'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'total'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'frequency'\n",
      " type: 'INTEGER'>]>\n",
      " selfLink: 'https://www.googleapis.com/bigquery/v2/projects/responsive-cab-267123/datasets/instacart_modeled/tables/Order_Products_Beam'\n",
      " tableReference: <TableReference\n",
      " datasetId: 'instacart_modeled'\n",
      " projectId: 'responsive-cab-267123'\n",
      " tableId: 'Order_Products_Beam'>\n",
      " type: 'TABLE'>.\n",
      "WARNING:apache_beam.io.gcp.bigquery_tools:Sleeping for 150 seconds before the write as BigQuery inserts can be routed to deleted table for 2 mins after the delete and create.\n"
     ]
    }
   ],
   "source": [
    "%run Order_Products_beam.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.options.pipeline_options:--region not set; will default to us-central1. Future releases of Beam will require the user to set --region explicitly, or else have a default set via the gcloud tool. https://cloud.google.com/compute/docs/regions-zones\n",
      "/home/jupyter/venv/lib/python3.5/site-packages/apache_beam/runners/dataflow/dataflow_runner.py:740: BeamDeprecationWarning: BigQuerySink is deprecated since 2.11.0. Use WriteToBigQuery instead.\n",
      "  kms_key=transform.kms_key))\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Starting GCS upload to gs://bmease_cs327e/staging/orders-df1.1583730903.426188/pipeline.pb...\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Completed GCS upload to gs://bmease_cs327e/staging/orders-df1.1583730903.426188/pipeline.pb in 0 seconds.\n",
      "INFO:apache_beam.runners.portability.stager:Downloading source distribution of the SDK from PyPi\n",
      "INFO:apache_beam.runners.portability.stager:Executing command: ['/home/jupyter/venv/bin/python', '-m', 'pip', 'download', '--dest', '/tmp/tmpgokvahky', 'apache-beam==2.19.0', '--no-deps', '--no-binary', ':all:']\n",
      "INFO:apache_beam.runners.portability.stager:Staging SDK sources from PyPI to gs://bmease_cs327e/staging/orders-df1.1583730903.426188/dataflow_python_sdk.tar\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Starting GCS upload to gs://bmease_cs327e/staging/orders-df1.1583730903.426188/dataflow_python_sdk.tar...\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Completed GCS upload to gs://bmease_cs327e/staging/orders-df1.1583730903.426188/dataflow_python_sdk.tar in 0 seconds.\n",
      "INFO:apache_beam.runners.portability.stager:Downloading binary distribution of the SDK from PyPi\n",
      "INFO:apache_beam.runners.portability.stager:Executing command: ['/home/jupyter/venv/bin/python', '-m', 'pip', 'download', '--dest', '/tmp/tmpgokvahky', 'apache-beam==2.19.0', '--no-deps', '--only-binary', ':all:', '--python-version', '35', '--implementation', 'cp', '--abi', 'cp35m', '--platform', 'manylinux1_x86_64']\n",
      "INFO:apache_beam.runners.portability.stager:Staging binary distribution of the SDK from PyPI to gs://bmease_cs327e/staging/orders-df1.1583730903.426188/apache_beam-2.19.0-cp35-cp35m-manylinux1_x86_64.whl\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Starting GCS upload to gs://bmease_cs327e/staging/orders-df1.1583730903.426188/apache_beam-2.19.0-cp35-cp35m-manylinux1_x86_64.whl...\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Completed GCS upload to gs://bmease_cs327e/staging/orders-df1.1583730903.426188/apache_beam-2.19.0-cp35-cp35m-manylinux1_x86_64.whl in 1 seconds.\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Create job: <Job\n",
      " createTime: '2020-03-09T05:15:11.251406Z'\n",
      " currentStateTime: '1970-01-01T00:00:00Z'\n",
      " id: '2020-03-08_22_15_10-17100944588761653355'\n",
      " location: 'us-central1'\n",
      " name: 'orders-df1'\n",
      " projectId: 'responsive-cab-267123'\n",
      " stageStates: []\n",
      " startTime: '2020-03-09T05:15:11.251406Z'\n",
      " steps: []\n",
      " tempFiles: []\n",
      " type: TypeValueValuesEnum(JOB_TYPE_BATCH, 1)>\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Created job with id: [2020-03-08_22_15_10-17100944588761653355]\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:To access the Dataflow monitoring console, please navigate to https://console.cloud.google.com/dataflow/jobsDetail/locations/us-central1/jobs/2020-03-08_22_15_10-17100944588761653355?project=responsive-cab-267123\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:Job 2020-03-08_22_15_10-17100944588761653355 is in state JOB_STATE_PENDING\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:15:10.128Z: JOB_MESSAGE_DETAILED: Autoscaling was automatically enabled for job 2020-03-08_22_15_10-17100944588761653355.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:15:10.128Z: JOB_MESSAGE_DETAILED: Autoscaling is enabled for job 2020-03-08_22_15_10-17100944588761653355. The number of workers will be between 1 and 1000.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:15:14.084Z: JOB_MESSAGE_DETAILED: Checking permissions granted to controller Service Account.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:15:14.710Z: JOB_MESSAGE_BASIC: Worker configuration: n1-standard-1 in us-central1-f.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:15:15.308Z: JOB_MESSAGE_DETAILED: Expanding CoGroupByKey operations into optimizable parts.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:15:15.338Z: JOB_MESSAGE_DEBUG: Combiner lifting skipped for step Write log 4/Write/WriteImpl/GroupByKey: GroupByKey not followed by a combiner.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:15:15.364Z: JOB_MESSAGE_DEBUG: Combiner lifting skipped for step Write log 3/Write/WriteImpl/GroupByKey: GroupByKey not followed by a combiner.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:15:15.392Z: JOB_MESSAGE_DEBUG: Combiner lifting skipped for step Group by product_id: GroupByKey output consumer count not exactly one.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:15:15.413Z: JOB_MESSAGE_DEBUG: Combiner lifting skipped for step Write to output.txt/Write/WriteImpl/GroupByKey: GroupByKey not followed by a combiner.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:15:15.438Z: JOB_MESSAGE_DEBUG: Combiner lifting skipped for step Write to input.txt/Write/WriteImpl/GroupByKey: GroupByKey not followed by a combiner.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:15:15.476Z: JOB_MESSAGE_DETAILED: Expanding GroupByKey operations into optimizable parts.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:15:15.502Z: JOB_MESSAGE_DETAILED: Lifting ValueCombiningMappingFns into MergeBucketsMappingFns\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:15:15.667Z: JOB_MESSAGE_DEBUG: Annotating graph with Autotuner information.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:15:15.952Z: JOB_MESSAGE_DETAILED: Fusing adjacent ParDo, Read, Write, and Flatten operations\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:15:15.974Z: JOB_MESSAGE_DETAILED: Fusing consumer Count Orders into Read from BigQuery\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:15:16.006Z: JOB_MESSAGE_DETAILED: Fusing consumer Write to input.txt/Write/WriteImpl/WriteBundles/WriteBundles into Read from BigQuery\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:15:16.036Z: JOB_MESSAGE_DETAILED: Fusing consumer Write to output.txt/Write/WriteImpl/WriteBundles/WriteBundles into Count Orders\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:15:16.061Z: JOB_MESSAGE_DETAILED: Fusing consumer Group by product_id/Reify into Count Orders\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:15:16.086Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 3/Write/WriteImpl/WriteBundles/WriteBundles into Group by product_id/GroupByWindow\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:15:16.116Z: JOB_MESSAGE_DETAILED: Fusing consumer Count product counts and frequencies into Group by product_id/GroupByWindow\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:15:16.140Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 4/Write/WriteImpl/WriteBundles/WriteBundles into Count product counts and frequencies\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:15:16.167Z: JOB_MESSAGE_DETAILED: Fusing consumer Write BQ table/WriteToBigQuery/NativeWrite into Count product counts and frequencies\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:15:16.199Z: JOB_MESSAGE_DETAILED: Fusing consumer Write to input.txt/Write/WriteImpl/Pair into Write to input.txt/Write/WriteImpl/WriteBundles/WriteBundles\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:15:16.229Z: JOB_MESSAGE_DETAILED: Fusing consumer Write to input.txt/Write/WriteImpl/WindowInto(WindowIntoFn) into Write to input.txt/Write/WriteImpl/Pair\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:15:16.257Z: JOB_MESSAGE_DETAILED: Fusing consumer Write to input.txt/Write/WriteImpl/GroupByKey/Reify into Write to input.txt/Write/WriteImpl/WindowInto(WindowIntoFn)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:15:16.282Z: JOB_MESSAGE_DETAILED: Fusing consumer Write to input.txt/Write/WriteImpl/GroupByKey/Write into Write to input.txt/Write/WriteImpl/GroupByKey/Reify\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:15:16.310Z: JOB_MESSAGE_DETAILED: Fusing consumer Write to input.txt/Write/WriteImpl/GroupByKey/GroupByWindow into Write to input.txt/Write/WriteImpl/GroupByKey/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:15:16.341Z: JOB_MESSAGE_DETAILED: Fusing consumer Write to input.txt/Write/WriteImpl/Extract into Write to input.txt/Write/WriteImpl/GroupByKey/GroupByWindow\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:15:16.366Z: JOB_MESSAGE_DETAILED: Fusing consumer Write to output.txt/Write/WriteImpl/Pair into Write to output.txt/Write/WriteImpl/WriteBundles/WriteBundles\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:15:16.387Z: JOB_MESSAGE_DETAILED: Fusing consumer Write to output.txt/Write/WriteImpl/WindowInto(WindowIntoFn) into Write to output.txt/Write/WriteImpl/Pair\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:15:16.409Z: JOB_MESSAGE_DETAILED: Fusing consumer Write to output.txt/Write/WriteImpl/GroupByKey/Reify into Write to output.txt/Write/WriteImpl/WindowInto(WindowIntoFn)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:15:16.431Z: JOB_MESSAGE_DETAILED: Fusing consumer Write to output.txt/Write/WriteImpl/GroupByKey/Write into Write to output.txt/Write/WriteImpl/GroupByKey/Reify\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:15:16.453Z: JOB_MESSAGE_DETAILED: Fusing consumer Write to output.txt/Write/WriteImpl/GroupByKey/GroupByWindow into Write to output.txt/Write/WriteImpl/GroupByKey/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:15:16.475Z: JOB_MESSAGE_DETAILED: Fusing consumer Write to output.txt/Write/WriteImpl/Extract into Write to output.txt/Write/WriteImpl/GroupByKey/GroupByWindow\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:15:16.503Z: JOB_MESSAGE_DETAILED: Fusing consumer Group by product_id/Write into Group by product_id/Reify\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:Job 2020-03-08_22_15_10-17100944588761653355 is in state JOB_STATE_RUNNING\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:15:16.535Z: JOB_MESSAGE_DETAILED: Fusing consumer Group by product_id/GroupByWindow into Group by product_id/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:15:16.558Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 3/Write/WriteImpl/Pair into Write log 3/Write/WriteImpl/WriteBundles/WriteBundles\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:15:16.585Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 3/Write/WriteImpl/WindowInto(WindowIntoFn) into Write log 3/Write/WriteImpl/Pair\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:15:16.617Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 3/Write/WriteImpl/GroupByKey/Reify into Write log 3/Write/WriteImpl/WindowInto(WindowIntoFn)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:15:16.644Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 3/Write/WriteImpl/GroupByKey/Write into Write log 3/Write/WriteImpl/GroupByKey/Reify\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:15:16.665Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 3/Write/WriteImpl/GroupByKey/GroupByWindow into Write log 3/Write/WriteImpl/GroupByKey/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:15:16.689Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 3/Write/WriteImpl/Extract into Write log 3/Write/WriteImpl/GroupByKey/GroupByWindow\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:15:16.712Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 4/Write/WriteImpl/Pair into Write log 4/Write/WriteImpl/WriteBundles/WriteBundles\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:15:16.738Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 4/Write/WriteImpl/WindowInto(WindowIntoFn) into Write log 4/Write/WriteImpl/Pair\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:15:16.760Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 4/Write/WriteImpl/GroupByKey/Reify into Write log 4/Write/WriteImpl/WindowInto(WindowIntoFn)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:15:16.786Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 4/Write/WriteImpl/GroupByKey/Write into Write log 4/Write/WriteImpl/GroupByKey/Reify\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:15:16.823Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 4/Write/WriteImpl/GroupByKey/GroupByWindow into Write log 4/Write/WriteImpl/GroupByKey/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:15:16.851Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 4/Write/WriteImpl/Extract into Write log 4/Write/WriteImpl/GroupByKey/GroupByWindow\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:15:16.874Z: JOB_MESSAGE_DETAILED: Fusing consumer Write to input.txt/Write/WriteImpl/InitializeWrite into Write to input.txt/Write/WriteImpl/DoOnce/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:15:16.901Z: JOB_MESSAGE_DETAILED: Fusing consumer Write to output.txt/Write/WriteImpl/InitializeWrite into Write to output.txt/Write/WriteImpl/DoOnce/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:15:16.934Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 3/Write/WriteImpl/InitializeWrite into Write log 3/Write/WriteImpl/DoOnce/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:15:16.957Z: JOB_MESSAGE_DETAILED: Fusing consumer Write log 4/Write/WriteImpl/InitializeWrite into Write log 4/Write/WriteImpl/DoOnce/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:15:16.989Z: JOB_MESSAGE_DEBUG: Workflow config is missing a default resource spec.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:15:17.016Z: JOB_MESSAGE_DEBUG: Adding StepResource setup and teardown to workflow graph.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:15:17.038Z: JOB_MESSAGE_DEBUG: Adding workflow start and stop steps.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:15:17.064Z: JOB_MESSAGE_DEBUG: Assigning stage ids.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:15:17.241Z: JOB_MESSAGE_DEBUG: Executing wait step start65\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:15:17.298Z: JOB_MESSAGE_BASIC: Executing operation Write log 4/Write/WriteImpl/DoOnce/Read+Write log 4/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:15:17.324Z: JOB_MESSAGE_BASIC: Executing operation Write log 3/Write/WriteImpl/DoOnce/Read+Write log 3/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:15:17.334Z: JOB_MESSAGE_DEBUG: Starting worker pool setup.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:15:17.353Z: JOB_MESSAGE_BASIC: Executing operation Write to output.txt/Write/WriteImpl/DoOnce/Read+Write to output.txt/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:15:17.354Z: JOB_MESSAGE_BASIC: Starting 1 workers in us-central1-f...\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:15:17.382Z: JOB_MESSAGE_BASIC: Executing operation Write to input.txt/Write/WriteImpl/DoOnce/Read+Write to input.txt/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:15:17.404Z: JOB_MESSAGE_BASIC: Executing operation Write to output.txt/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:15:17.435Z: JOB_MESSAGE_BASIC: Executing operation Group by product_id/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:15:17.451Z: JOB_MESSAGE_BASIC: Finished operation Write to output.txt/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:15:17.465Z: JOB_MESSAGE_BASIC: Executing operation Write log 3/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:15:17.485Z: JOB_MESSAGE_BASIC: Finished operation Group by product_id/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:15:17.489Z: JOB_MESSAGE_BASIC: Executing operation Write log 4/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:15:17.518Z: JOB_MESSAGE_BASIC: Executing operation Write to input.txt/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:15:17.522Z: JOB_MESSAGE_BASIC: Finished operation Write log 3/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:15:17.547Z: JOB_MESSAGE_DEBUG: Value \"Write to output.txt/Write/WriteImpl/GroupByKey/Session\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:15:17.547Z: JOB_MESSAGE_BASIC: Finished operation Write log 4/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:15:17.574Z: JOB_MESSAGE_DEBUG: Value \"Group by product_id/Session\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:15:17.579Z: JOB_MESSAGE_BASIC: Finished operation Write to input.txt/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:15:17.606Z: JOB_MESSAGE_DEBUG: Value \"Write log 3/Write/WriteImpl/GroupByKey/Session\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:15:17.634Z: JOB_MESSAGE_DEBUG: Value \"Write log 4/Write/WriteImpl/GroupByKey/Session\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:15:17.663Z: JOB_MESSAGE_DEBUG: Value \"Write to input.txt/Write/WriteImpl/GroupByKey/Session\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:15:48.773Z: JOB_MESSAGE_DETAILED: Autoscaling: Raised the number of workers to 1 based on the rate of progress in the currently running step(s).\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:17:25.767Z: JOB_MESSAGE_DETAILED: Workers have started successfully.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:17:25.804Z: JOB_MESSAGE_DETAILED: Workers have started successfully.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:18:13.181Z: JOB_MESSAGE_BASIC: Finished operation Write log 3/Write/WriteImpl/DoOnce/Read+Write log 3/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:18:13.243Z: JOB_MESSAGE_DEBUG: Value \"Write log 3/Write/WriteImpl/DoOnce/Read.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:18:13.271Z: JOB_MESSAGE_DEBUG: Value \"Write log 3/Write/WriteImpl/InitializeWrite.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:18:13.338Z: JOB_MESSAGE_BASIC: Executing operation Write log 3/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:18:13.364Z: JOB_MESSAGE_BASIC: Executing operation Write log 3/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:18:13.393Z: JOB_MESSAGE_BASIC: Finished operation Write log 3/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:18:13.398Z: JOB_MESSAGE_BASIC: Executing operation Write log 3/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:18:13.426Z: JOB_MESSAGE_BASIC: Finished operation Write log 3/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:18:13.449Z: JOB_MESSAGE_BASIC: Finished operation Write log 3/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:18:13.462Z: JOB_MESSAGE_DEBUG: Value \"Write log 3/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:18:13.490Z: JOB_MESSAGE_DEBUG: Value \"Write log 3/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:18:13.524Z: JOB_MESSAGE_DEBUG: Value \"Write log 3/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:18:16.754Z: JOB_MESSAGE_BASIC: Finished operation Write to output.txt/Write/WriteImpl/DoOnce/Read+Write to output.txt/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:18:16.813Z: JOB_MESSAGE_DEBUG: Value \"Write to output.txt/Write/WriteImpl/DoOnce/Read.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:18:16.845Z: JOB_MESSAGE_DEBUG: Value \"Write to output.txt/Write/WriteImpl/InitializeWrite.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:18:16.905Z: JOB_MESSAGE_BASIC: Executing operation Write to output.txt/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:18:16.936Z: JOB_MESSAGE_BASIC: Executing operation Write to output.txt/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:18:16.954Z: JOB_MESSAGE_BASIC: Finished operation Write to output.txt/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:18:16.969Z: JOB_MESSAGE_BASIC: Executing operation Write to output.txt/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:18:16.999Z: JOB_MESSAGE_BASIC: Finished operation Write to output.txt/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:18:17.012Z: JOB_MESSAGE_BASIC: Finished operation Write to output.txt/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:18:17.020Z: JOB_MESSAGE_DEBUG: Value \"Write to output.txt/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:18:17.062Z: JOB_MESSAGE_DEBUG: Value \"Write to output.txt/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:18:17.098Z: JOB_MESSAGE_DEBUG: Value \"Write to output.txt/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:18:20.283Z: JOB_MESSAGE_BASIC: Finished operation Write log 4/Write/WriteImpl/DoOnce/Read+Write log 4/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:18:20.415Z: JOB_MESSAGE_DEBUG: Value \"Write log 4/Write/WriteImpl/DoOnce/Read.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:18:20.454Z: JOB_MESSAGE_DEBUG: Value \"Write log 4/Write/WriteImpl/InitializeWrite.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:18:20.543Z: JOB_MESSAGE_BASIC: Executing operation Write log 4/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:18:20.597Z: JOB_MESSAGE_BASIC: Executing operation Write log 4/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:18:20.626Z: JOB_MESSAGE_BASIC: Finished operation Write log 4/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:18:20.640Z: JOB_MESSAGE_BASIC: Executing operation Write log 4/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:18:20.658Z: JOB_MESSAGE_BASIC: Finished operation Write log 4/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:18:20.716Z: JOB_MESSAGE_BASIC: Finished operation Write log 4/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:18:20.718Z: JOB_MESSAGE_DEBUG: Value \"Write log 4/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:18:20.766Z: JOB_MESSAGE_DEBUG: Value \"Write log 4/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:18:20.828Z: JOB_MESSAGE_DEBUG: Value \"Write log 4/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:18:23.865Z: JOB_MESSAGE_BASIC: Finished operation Write to input.txt/Write/WriteImpl/DoOnce/Read+Write to input.txt/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:18:23.953Z: JOB_MESSAGE_DEBUG: Value \"Write to input.txt/Write/WriteImpl/DoOnce/Read.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:18:23.992Z: JOB_MESSAGE_DEBUG: Value \"Write to input.txt/Write/WriteImpl/InitializeWrite.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:18:24.076Z: JOB_MESSAGE_BASIC: Executing operation Write to input.txt/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:18:24.117Z: JOB_MESSAGE_BASIC: Executing operation Write to input.txt/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:18:24.123Z: JOB_MESSAGE_BASIC: Finished operation Write to input.txt/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:18:24.162Z: JOB_MESSAGE_BASIC: Executing operation Write to input.txt/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:18:24.179Z: JOB_MESSAGE_BASIC: Finished operation Write to input.txt/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:18:24.215Z: JOB_MESSAGE_DEBUG: Value \"Write to input.txt/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:18:24.226Z: JOB_MESSAGE_BASIC: Finished operation Write to input.txt/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:18:24.266Z: JOB_MESSAGE_DEBUG: Value \"Write to input.txt/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:18:24.313Z: JOB_MESSAGE_DEBUG: Value \"Write to input.txt/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:18:24.360Z: JOB_MESSAGE_BASIC: Executing operation Read from BigQuery+Count Orders+Write to input.txt/Write/WriteImpl/WriteBundles/WriteBundles+Write to output.txt/Write/WriteImpl/WriteBundles/WriteBundles+Group by product_id/Reify+Write to input.txt/Write/WriteImpl/Pair+Write to input.txt/Write/WriteImpl/WindowInto(WindowIntoFn)+Write to input.txt/Write/WriteImpl/GroupByKey/Reify+Write to input.txt/Write/WriteImpl/GroupByKey/Write+Write to output.txt/Write/WriteImpl/Pair+Write to output.txt/Write/WriteImpl/WindowInto(WindowIntoFn)+Write to output.txt/Write/WriteImpl/GroupByKey/Reify+Write to output.txt/Write/WriteImpl/GroupByKey/Write+Group by product_id/Write\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:18:24.503Z: JOB_MESSAGE_BASIC: BigQuery query issued as job: \"dataflow_job_5140624787852767089\". You can check its status with the bq tool: \"bq show -j --project_id=responsive-cab-267123 dataflow_job_5140624787852767089\".\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:19:45.751Z: JOB_MESSAGE_BASIC: BigQuery query completed, job : \"dataflow_job_5140624787852767089\"\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:19:46.155Z: JOB_MESSAGE_BASIC: BigQuery export job \"dataflow_job_15294873314646102917\" started. You can check its status with the bq tool: \"bq show -j --project_id=responsive-cab-267123 dataflow_job_15294873314646102917\".\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:20:16.452Z: JOB_MESSAGE_DETAILED: BigQuery export job progress: \"dataflow_job_15294873314646102917\" observed total of 4 exported files thus far.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:20:16.533Z: JOB_MESSAGE_BASIC: BigQuery export job finished: \"dataflow_job_15294873314646102917\"\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:21:17.228Z: JOB_MESSAGE_DETAILED: Checking permissions granted to controller Service Account.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:21:53.458Z: JOB_MESSAGE_BASIC: Autoscaling: Resizing worker pool from 1 to 8.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:21:59.247Z: JOB_MESSAGE_DETAILED: Autoscaling: Raised the number of workers to 8 based on the rate of progress in the currently running step(s).\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:27:17.225Z: JOB_MESSAGE_DETAILED: Checking permissions granted to controller Service Account.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:28:07.295Z: JOB_MESSAGE_BASIC: Finished operation Read from BigQuery+Count Orders+Write to input.txt/Write/WriteImpl/WriteBundles/WriteBundles+Write to output.txt/Write/WriteImpl/WriteBundles/WriteBundles+Group by product_id/Reify+Write to input.txt/Write/WriteImpl/Pair+Write to input.txt/Write/WriteImpl/WindowInto(WindowIntoFn)+Write to input.txt/Write/WriteImpl/GroupByKey/Reify+Write to input.txt/Write/WriteImpl/GroupByKey/Write+Write to output.txt/Write/WriteImpl/Pair+Write to output.txt/Write/WriteImpl/WindowInto(WindowIntoFn)+Write to output.txt/Write/WriteImpl/GroupByKey/Reify+Write to output.txt/Write/WriteImpl/GroupByKey/Write+Group by product_id/Write\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:28:07.377Z: JOB_MESSAGE_BASIC: Executing operation Write to output.txt/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:28:07.469Z: JOB_MESSAGE_BASIC: Executing operation Group by product_id/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:28:07.488Z: JOB_MESSAGE_BASIC: Finished operation Write to output.txt/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:28:07.500Z: JOB_MESSAGE_BASIC: Executing operation Write to input.txt/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:28:07.520Z: JOB_MESSAGE_BASIC: Finished operation Group by product_id/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:28:07.538Z: JOB_MESSAGE_BASIC: Finished operation Write to input.txt/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:28:07.543Z: JOB_MESSAGE_BASIC: Executing operation Write to output.txt/Write/WriteImpl/GroupByKey/Read+Write to output.txt/Write/WriteImpl/GroupByKey/GroupByWindow+Write to output.txt/Write/WriteImpl/Extract\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:28:07.582Z: JOB_MESSAGE_BASIC: Executing operation Group by product_id/Read+Group by product_id/GroupByWindow+Write log 3/Write/WriteImpl/WriteBundles/WriteBundles+Count product counts and frequencies+Write log 4/Write/WriteImpl/WriteBundles/WriteBundles+Write BQ table/WriteToBigQuery/NativeWrite+Write log 3/Write/WriteImpl/Pair+Write log 3/Write/WriteImpl/WindowInto(WindowIntoFn)+Write log 3/Write/WriteImpl/GroupByKey/Reify+Write log 3/Write/WriteImpl/GroupByKey/Write+Write log 4/Write/WriteImpl/Pair+Write log 4/Write/WriteImpl/WindowInto(WindowIntoFn)+Write log 4/Write/WriteImpl/GroupByKey/Reify+Write log 4/Write/WriteImpl/GroupByKey/Write\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:28:07.606Z: JOB_MESSAGE_BASIC: Executing operation Write to input.txt/Write/WriteImpl/GroupByKey/Read+Write to input.txt/Write/WriteImpl/GroupByKey/GroupByWindow+Write to input.txt/Write/WriteImpl/Extract\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:28:08.904Z: JOB_MESSAGE_BASIC: Finished operation Write to output.txt/Write/WriteImpl/GroupByKey/Read+Write to output.txt/Write/WriteImpl/GroupByKey/GroupByWindow+Write to output.txt/Write/WriteImpl/Extract\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:28:08.963Z: JOB_MESSAGE_DEBUG: Value \"Write to output.txt/Write/WriteImpl/Extract.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:28:09.015Z: JOB_MESSAGE_BASIC: Executing operation Write to output.txt/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:28:09.041Z: JOB_MESSAGE_BASIC: Executing operation Write to output.txt/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:28:09.060Z: JOB_MESSAGE_BASIC: Finished operation Write to output.txt/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:28:09.101Z: JOB_MESSAGE_BASIC: Finished operation Write to output.txt/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:28:09.212Z: JOB_MESSAGE_BASIC: Finished operation Write to input.txt/Write/WriteImpl/GroupByKey/Read+Write to input.txt/Write/WriteImpl/GroupByKey/GroupByWindow+Write to input.txt/Write/WriteImpl/Extract\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:28:09.255Z: JOB_MESSAGE_DEBUG: Value \"Write to output.txt/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:28:09.361Z: JOB_MESSAGE_DEBUG: Value \"Write to output.txt/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:28:09.437Z: JOB_MESSAGE_DEBUG: Value \"Write to input.txt/Write/WriteImpl/Extract.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:28:09.474Z: JOB_MESSAGE_BASIC: Executing operation Write to output.txt/Write/WriteImpl/PreFinalize/PreFinalize\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:28:09.505Z: JOB_MESSAGE_BASIC: Executing operation Write to input.txt/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:28:09.528Z: JOB_MESSAGE_BASIC: Executing operation Write to input.txt/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:28:09.548Z: JOB_MESSAGE_BASIC: Finished operation Write to input.txt/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:28:09.569Z: JOB_MESSAGE_BASIC: Finished operation Write to input.txt/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:28:09.610Z: JOB_MESSAGE_DEBUG: Value \"Write to input.txt/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:28:09.634Z: JOB_MESSAGE_DEBUG: Value \"Write to input.txt/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:28:09.689Z: JOB_MESSAGE_BASIC: Executing operation Write to input.txt/Write/WriteImpl/PreFinalize/PreFinalize\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:28:11.239Z: JOB_MESSAGE_BASIC: Finished operation Write to output.txt/Write/WriteImpl/PreFinalize/PreFinalize\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:28:11.293Z: JOB_MESSAGE_DEBUG: Value \"Write to output.txt/Write/WriteImpl/PreFinalize.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:28:11.350Z: JOB_MESSAGE_BASIC: Executing operation Write to output.txt/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:28:11.396Z: JOB_MESSAGE_BASIC: Finished operation Write to output.txt/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:28:11.449Z: JOB_MESSAGE_DEBUG: Value \"Write to output.txt/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:28:11.506Z: JOB_MESSAGE_BASIC: Executing operation Write to output.txt/Write/WriteImpl/FinalizeWrite/FinalizeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:28:11.507Z: JOB_MESSAGE_BASIC: Finished operation Write to input.txt/Write/WriteImpl/PreFinalize/PreFinalize\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:28:11.569Z: JOB_MESSAGE_DEBUG: Value \"Write to input.txt/Write/WriteImpl/PreFinalize.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:28:11.620Z: JOB_MESSAGE_BASIC: Executing operation Write to input.txt/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:28:11.659Z: JOB_MESSAGE_BASIC: Finished operation Write to input.txt/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:28:11.712Z: JOB_MESSAGE_DEBUG: Value \"Write to input.txt/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:28:11.759Z: JOB_MESSAGE_BASIC: Executing operation Write to input.txt/Write/WriteImpl/FinalizeWrite/FinalizeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:28:13.578Z: JOB_MESSAGE_BASIC: Finished operation Write to output.txt/Write/WriteImpl/FinalizeWrite/FinalizeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:28:13.768Z: JOB_MESSAGE_BASIC: Finished operation Write to input.txt/Write/WriteImpl/FinalizeWrite/FinalizeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:29:13.407Z: JOB_MESSAGE_BASIC: Executing BigQuery import job \"dataflow_job_5140624787852765195\". You can check its status with the bq tool: \"bq show -j --project_id=responsive-cab-267123 dataflow_job_5140624787852765195\".\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:29:24.040Z: JOB_MESSAGE_BASIC: BigQuery import job \"dataflow_job_5140624787852765195\" done.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:29:24.441Z: JOB_MESSAGE_BASIC: Finished operation Group by product_id/Read+Group by product_id/GroupByWindow+Write log 3/Write/WriteImpl/WriteBundles/WriteBundles+Count product counts and frequencies+Write log 4/Write/WriteImpl/WriteBundles/WriteBundles+Write BQ table/WriteToBigQuery/NativeWrite+Write log 3/Write/WriteImpl/Pair+Write log 3/Write/WriteImpl/WindowInto(WindowIntoFn)+Write log 3/Write/WriteImpl/GroupByKey/Reify+Write log 3/Write/WriteImpl/GroupByKey/Write+Write log 4/Write/WriteImpl/Pair+Write log 4/Write/WriteImpl/WindowInto(WindowIntoFn)+Write log 4/Write/WriteImpl/GroupByKey/Reify+Write log 4/Write/WriteImpl/GroupByKey/Write\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:29:24.539Z: JOB_MESSAGE_BASIC: Executing operation Write log 4/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:29:24.567Z: JOB_MESSAGE_BASIC: Executing operation Write log 3/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:29:24.597Z: JOB_MESSAGE_BASIC: Finished operation Write log 4/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:29:24.640Z: JOB_MESSAGE_BASIC: Finished operation Write log 3/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:29:24.677Z: JOB_MESSAGE_BASIC: Executing operation Write log 4/Write/WriteImpl/GroupByKey/Read+Write log 4/Write/WriteImpl/GroupByKey/GroupByWindow+Write log 4/Write/WriteImpl/Extract\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:29:24.713Z: JOB_MESSAGE_BASIC: Executing operation Write log 3/Write/WriteImpl/GroupByKey/Read+Write log 3/Write/WriteImpl/GroupByKey/GroupByWindow+Write log 3/Write/WriteImpl/Extract\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:29:25.870Z: JOB_MESSAGE_BASIC: Finished operation Write log 3/Write/WriteImpl/GroupByKey/Read+Write log 3/Write/WriteImpl/GroupByKey/GroupByWindow+Write log 3/Write/WriteImpl/Extract\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:29:25.934Z: JOB_MESSAGE_DEBUG: Value \"Write log 3/Write/WriteImpl/Extract.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:29:25.994Z: JOB_MESSAGE_BASIC: Executing operation Write log 3/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:29:26.001Z: JOB_MESSAGE_BASIC: Finished operation Write log 4/Write/WriteImpl/GroupByKey/Read+Write log 4/Write/WriteImpl/GroupByKey/GroupByWindow+Write log 4/Write/WriteImpl/Extract\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:29:26.025Z: JOB_MESSAGE_BASIC: Executing operation Write log 3/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:29:26.043Z: JOB_MESSAGE_BASIC: Finished operation Write log 3/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:29:26.058Z: JOB_MESSAGE_DEBUG: Value \"Write log 4/Write/WriteImpl/Extract.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:29:26.066Z: JOB_MESSAGE_BASIC: Finished operation Write log 3/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:29:26.098Z: JOB_MESSAGE_DEBUG: Value \"Write log 3/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:29:26.121Z: JOB_MESSAGE_DEBUG: Value \"Write log 3/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:29:26.148Z: JOB_MESSAGE_BASIC: Executing operation Write log 4/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:29:26.177Z: JOB_MESSAGE_BASIC: Executing operation Write log 4/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:29:26.194Z: JOB_MESSAGE_BASIC: Finished operation Write log 4/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:29:26.202Z: JOB_MESSAGE_BASIC: Executing operation Write log 3/Write/WriteImpl/PreFinalize/PreFinalize\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:29:26.219Z: JOB_MESSAGE_BASIC: Finished operation Write log 4/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:29:26.253Z: JOB_MESSAGE_DEBUG: Value \"Write log 4/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:29:26.278Z: JOB_MESSAGE_DEBUG: Value \"Write log 4/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:29:26.335Z: JOB_MESSAGE_BASIC: Executing operation Write log 4/Write/WriteImpl/PreFinalize/PreFinalize\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:29:27.888Z: JOB_MESSAGE_BASIC: Finished operation Write log 3/Write/WriteImpl/PreFinalize/PreFinalize\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:29:27.939Z: JOB_MESSAGE_DEBUG: Value \"Write log 3/Write/WriteImpl/PreFinalize.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:29:27.963Z: JOB_MESSAGE_BASIC: Finished operation Write log 4/Write/WriteImpl/PreFinalize/PreFinalize\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:29:27.999Z: JOB_MESSAGE_BASIC: Executing operation Write log 3/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:29:28.028Z: JOB_MESSAGE_DEBUG: Value \"Write log 4/Write/WriteImpl/PreFinalize.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:29:28.044Z: JOB_MESSAGE_BASIC: Finished operation Write log 3/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:29:28.088Z: JOB_MESSAGE_BASIC: Executing operation Write log 4/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:29:28.112Z: JOB_MESSAGE_DEBUG: Value \"Write log 3/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:29:28.134Z: JOB_MESSAGE_BASIC: Finished operation Write log 4/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:29:28.172Z: JOB_MESSAGE_BASIC: Executing operation Write log 3/Write/WriteImpl/FinalizeWrite/FinalizeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:29:28.196Z: JOB_MESSAGE_DEBUG: Value \"Write log 4/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:29:28.254Z: JOB_MESSAGE_BASIC: Executing operation Write log 4/Write/WriteImpl/FinalizeWrite/FinalizeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:29:28.813Z: JOB_MESSAGE_DETAILED: Autoscaling: Reduced the number of workers to 7 based on the rate of progress in the currently running step(s).\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:29:29.768Z: JOB_MESSAGE_BASIC: Finished operation Write log 3/Write/WriteImpl/FinalizeWrite/FinalizeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:29:30.020Z: JOB_MESSAGE_BASIC: Finished operation Write log 4/Write/WriteImpl/FinalizeWrite/FinalizeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:29:30.079Z: JOB_MESSAGE_DEBUG: Executing success step success63\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:29:30.194Z: JOB_MESSAGE_DETAILED: Cleaning up.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:29:30.274Z: JOB_MESSAGE_DEBUG: Starting worker pool teardown.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:29:30.298Z: JOB_MESSAGE_BASIC: Stopping worker pool...\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:31:01.546Z: JOB_MESSAGE_DETAILED: Autoscaling: Resized worker pool from 7 to 0.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:31:01.596Z: JOB_MESSAGE_BASIC: Worker pool stopped.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-09T05:31:01.628Z: JOB_MESSAGE_DEBUG: Tearing down pending resources...\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:Job 2020-03-08_22_15_10-17100944588761653355 is in state JOB_STATE_DONE\n"
     ]
    }
   ],
   "source": [
    "%run Order_Products_beam_dataflow.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verifying Primary Keys in Order_Products_Beam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "select count(*) from instacart_modeled.Order_Products_Beam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "select count(distinct product_id) from instacart_modeled.Order_Products_Beam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verifying Primary Keys in Order_Products_Beam_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49685</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     f0_\n",
       "0  49685"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "select count(*) from instacart_modeled.Order_Products_Beam_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49685</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     f0_\n",
       "0  49685"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "select count(distinct product_id) from instacart_modeled.Order_Products_Beam_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (beam_venv)",
   "language": "python",
   "name": "beam_venv_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
